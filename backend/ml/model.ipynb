{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier as xgb_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_f1(y_true: list, y_pred: list):\n",
    "    \n",
    "    y_bin = [1. if y_cont > 0.5 else 0. for y_cont in y_pred] # binaryzing your output\n",
    "    \n",
    "    return 'f1', f1_score(y_true, y_bin)\n",
    "\n",
    "\n",
    "def eval_metrics(y_true: list, y_pred: list) -> dict:\n",
    "    \"\"\"\n",
    "    Function to calculate the classification metrics\n",
    "    \n",
    "        Args:\n",
    "            y_test: list, test subset\n",
    "            y_predicitons: list prediciton on x_test\n",
    "    \n",
    "        Returs:\n",
    "\n",
    "            dict with the keys:\n",
    "                confusion_matrix - confusion matrix\n",
    "                accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "                precision = TP/(TP+FP)\n",
    "                recall = TP/(TP+FN)\n",
    "                f1_score = 2/(1/recall+1/precision)\n",
    "                specifisity = TN/(TN+FP)\n",
    "                npv = TN/(TN+FN)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # total numb of true and false labels\n",
    "    labels_real = cm.sum(axis = 1)\n",
    "    labels_pred = cm.sum(axis = 0)\n",
    "    n_correct_labels = cm.diagonal().sum()\n",
    "    accuracy = n_correct_labels/len(y_true)\n",
    "    recall = cm[1,1]/labels_real[1]\n",
    "    precision = cm[1,1]/labels_pred[1]    \n",
    "    nvp = cm[0,0]/labels_pred[0]\n",
    "    specificity = cm[0,0]/labels_real[0]\n",
    "        \n",
    "    return {\"confusion_matrix\": cm,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": 2/(1/recall+1/precision),\n",
    "            \"specificity\": specificity,\n",
    "            \"npv\":nvp\n",
    "           } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('data/warm_cold_colors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle data\n",
    "seed = 2019\n",
    "\n",
    "dat = dat.sample(len(dat), random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dat.drop(columns='is_warm'), dat['is_warm'], \n",
    "                                                    test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": 'binary:logistic',\n",
    "    \"learning_rate\": 0.5, \n",
    "    \"n_estimators\": 100, \n",
    "    \"max_depth\": 3,\n",
    "    \"n_jobs\": 4,\n",
    "    \"silent\": False, \n",
    "    \"subsample\": 0.8,\n",
    "    \"random_state\": seed\n",
    "}\n",
    "\n",
    "model = xgb_class(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.5, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       random_state=2019, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=False, subsample=0.8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "metrics_train = eval_metrics(y_train, y_train_pred)\n",
    "metrics_test = eval_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[12,  1],\n",
       "        [ 1, 14]]),\n",
       " 'accuracy': 0.9285714285714286,\n",
       " 'recall': 0.9333333333333333,\n",
       " 'precision': 0.9333333333333333,\n",
       " 'f1_score': 0.9333333333333333,\n",
       " 'specificity': 0.9230769230769231,\n",
       " 'npv': 0.9230769230769231}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[55,  0],\n",
       "        [ 1, 52]]),\n",
       " 'accuracy': 0.9907407407407407,\n",
       " 'recall': 0.9811320754716981,\n",
       " 'precision': 1.0,\n",
       " 'f1_score': 0.9904761904761905,\n",
       " 'specificity': 1.0,\n",
       " 'npv': 0.9821428571428571}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('models/model_v2.xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(rgb:pd.DataFrame, model) -> float:\n",
    "    \n",
    "    _col = 'color_tone'\n",
    "    try:\n",
    "        rgb[_col] = pd.DataFrame(model.predict(rgb, validate_features=False)).\\\n",
    "                                replace([0, 1], [\"cool\", \"warm\"])\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return rgb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "      <th>color_tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>203</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r    g    b color_tone\n",
       "0  8  103  203       cool"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor(pd.DataFrame({'r':[8], 'g':[103], 'b':[203]}), model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
