{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBClassifier as xgb_class \n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true: list, y_pred: list) -> dict:\n",
    "    \"\"\"\n",
    "    Function to calculate the classification metrics\n",
    "    \n",
    "        Args:\n",
    "            y_test: list, test subset\n",
    "            y_predicitons: list prediciton on x_test\n",
    "    \n",
    "        Returs:\n",
    "\n",
    "            dict with the keys:\n",
    "                confusion_matrix - confusion matrix\n",
    "                accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "                precision = TP/(TP+FP)\n",
    "                recall = TP/(TP+FN)\n",
    "                f1_score = 2/(1/recall+1/precision)\n",
    "                specifisity = TN/(TN+FP)\n",
    "                npv = TN/(TN+FN)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # total numb of true and false labels\n",
    "    labels_real = cm.sum(axis = 1)\n",
    "    labels_pred = cm.sum(axis = 0)\n",
    "    n_correct_labels = cm.diagonal().sum()\n",
    "    accuracy = n_correct_labels/len(y_true)\n",
    "    recall = cm[1,1]/labels_real[1]\n",
    "    precision = cm[1,1]/labels_pred[1]    \n",
    "    nvp = cm[0,0]/labels_pred[0]\n",
    "    specificity = cm[0,0]/labels_real[0]\n",
    "        \n",
    "    return {\"confusion_matrix\": cm,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": 2/(1/recall+1/precision),\n",
    "            \"specificity\": specificity,\n",
    "            \"npv\":nvp\n",
    "           } \n",
    "\n",
    "def save_object(obj, filename):\n",
    "    \"\"\"\n",
    "    Function to save/pickle python object\n",
    "\n",
    "        Args:\n",
    "            filename: str path to pickle file\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def read_object(filename: str):\n",
    "    \"\"\"\n",
    "    Function to read/un-pickle python object\n",
    "\n",
    "        Args:\n",
    "            filename: str path to pickle file\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'rb') as input_stream:\n",
    "        obj = pickle.load(input_stream)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 4 columns):\n",
      "r          136 non-null int64\n",
      "g          136 non-null int64\n",
      "b          136 non-null int64\n",
      "is_warm    136 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 4.3 KB\n"
     ]
    }
   ],
   "source": [
    "# read the data to train the model\n",
    "dat = pd.read_csv('data/warm_cold_colors.csv')\n",
    "\n",
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "      <th>is_warm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     r    g    b  is_warm\n",
       "0  254   37    0        1\n",
       "1  221   39  123        1\n",
       "2  254   89    0        1\n",
       "3  254  153    0        1\n",
       "4  255  221    0        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle data\n",
    "seed = 2019\n",
    "\n",
    "dat = dat.sample(len(dat), random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dat.drop(columns='is_warm'), dat['is_warm'], \n",
    "                                                    test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.5, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       random_state=2019, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=False, subsample=0.8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init the model and train it\n",
    "\n",
    "params = {\n",
    "    \"objective\": 'binary:logistic',\n",
    "    \"learning_rate\": 0.5, \n",
    "    \"n_estimators\": 100, \n",
    "    \"max_depth\": 3,\n",
    "    \"n_jobs\": 4,\n",
    "    \"silent\": False, \n",
    "    \"subsample\": 0.8,\n",
    "    \"random_state\": seed\n",
    "}\n",
    "\n",
    "model = xgb_class(**params)\n",
    "\n",
    "model.fit(x_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict based on train set\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "# predict based on test set\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "metrics_train = eval_metrics(y_train, y_train_pred)\n",
    "metrics_test = eval_metrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[12,  1],\n",
       "        [ 1, 14]]),\n",
       " 'accuracy': 0.9285714285714286,\n",
       " 'recall': 0.9333333333333333,\n",
       " 'precision': 0.9333333333333333,\n",
       " 'f1_score': 0.9333333333333333,\n",
       " 'specificity': 0.9230769230769231,\n",
       " 'npv': 0.9230769230769231}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[55,  0],\n",
       "        [ 1, 52]]),\n",
       " 'accuracy': 0.9907407407407407,\n",
       " 'recall': 0.9811320754716981,\n",
       " 'precision': 1.0,\n",
       " 'f1_score': 0.9904761904761905,\n",
       " 'specificity': 1.0,\n",
       " 'npv': 0.9821428571428571}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(rgb:pd.DataFrame, model) -> float:\n",
    "    \n",
    "    _col = 'color_tone'\n",
    "    try:\n",
    "        rgb[_col] = pd.DataFrame(model.predict(rgb, validate_features=False)).\\\n",
    "                                replace([0, 1], [\"cool\", \"warm\"])\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return rgb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test color\n",
    "test_point = {'r': [8], 'g': [103], 'b': [203]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color is warm? False\n"
     ]
    }
   ],
   "source": [
    "# predict the category\n",
    "\n",
    "is_warm = model.predict(pd.DataFrame(test_point)).squeeze()\n",
    "\n",
    "print(f\"The color is warm? {bool(is_warm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, 'model/model_v1.xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
